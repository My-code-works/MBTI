{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Input\n",
    "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\n",
    "from keras_contrib.layers.crf import CRF\n",
    "from keras_contrib.utils import save_load_utils\n",
    "from keras_contrib.metrics import crf_accuracy\n",
    "from keras_contrib.losses import crf_loss\n",
    "from keras.utils import to_categorical\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import load_model\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "import pickle, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BERT_BASE = os.path.join(os.getcwd(), 'bert/bert_model/uncased_L-12_H-768_A-12')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMmodel:\n",
    "    def __init__(self, input_length, para_emb_dim, num_tags, hidden_dim=200, dropout=0.5):\n",
    "        self.num_tags = num_tags\n",
    "        self.model = Sequential()\n",
    "        self.model.add(Bidirectional(LSTM(hidden_dim, return_sequences=True), input_shape=(input_length, para_emb_dim)))\n",
    "        self.model.add(Dropout(dropout))\n",
    "        # self.model.add(Bidirectional(LSTM(hidden_dim, return_sequences=True), input_shape=(input_length, para_emb_dim)))\n",
    "        # self.model.add(Dropout(dropout))\n",
    "        self.model.add(TimeDistributed(Dense(self.num_tags)))\n",
    "        crf = CRF(self.num_tags)\n",
    "        self.model.add(crf)\n",
    "        self.model.compile('rmsprop', loss=crf_loss, metrics=[crf_accuracy])\n",
    "    \n",
    "    def save_model(self, filepath):\n",
    "        save_load_utils.save_all_weights(self.model, filepath)\n",
    "    \n",
    "    def restore_model(self, filepath):\n",
    "        save_load_utils.load_all_weights(self.model, filepath)\n",
    "        \n",
    "    def train(self, trainX, trainY, batch_size=32, epochs=10, validation_split=0.1, verbose=1):\n",
    "        return self.model.fit(trainX, np.array(trainY), batch_size=batch_size, epochs=epochs, \n",
    "                             validation_split=validation_split, verbose=verbose)\n",
    "    \n",
    "    @staticmethod\n",
    "    def myloss(y_true, y_pred):   \n",
    "        y_pred /= tf.reduce_sum(y_pred, -1, True)\n",
    "        # manual computation of crossentropy\n",
    "        y_pred = K.clip(y_pred, K.epsilon(), 1. - K.epsilon())\n",
    "        return -tf.reduce_sum(y_true * tf.log(y_pred), -1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114975 114975 114975\n"
     ]
    }
   ],
   "source": [
    "# from Dataprocessor import Dataprocessor\n",
    "\n",
    "# filelist = [('data/%d.json' % i) for i in range(500)]\n",
    "# processor = Dataprocessor()\n",
    "# train_texts, train_tags, train_rawtags = processor.load_data(filelist)\n",
    "\n",
    "# save_train_data(train_texts, train_tags, train_rawtags)\n",
    "train_texts, train_tags, train_rawtags = load_train_data()\n",
    "print(len(train_texts), len(train_tags), len(train_rawtags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert_utils import get_all_features\n",
    "\n",
    "bert_config_file = os.path.join(BERT_BASE, 'bert_config.json')\n",
    "vocab_file = os.path.join(BERT_BASE, 'vocab.txt')\n",
    "bert_checkpoint = os.path.join(BERT_BASE, 'bert_model.ckpt')\n",
    "    \n",
    "# feature = get_all_features(train_texts[:], bert_config_file, vocab_file, bert_checkpoint)\n",
    "# with open('save_model/feature_1.pk', 'rb') as f:\n",
    "#     feature = pickle.load(f)\n",
    "# print(len(feature))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional_1 (Bidirection (None, 100, 400)          1550400   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100, 400)          0         \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 100, 12)           4812      \n",
      "_________________________________________________________________\n",
      "crf_1 (CRF)                  (None, 100, 12)           324       \n",
      "=================================================================\n",
      "Total params: 1,555,536\n",
      "Trainable params: 1,555,536\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "INPUT_LENGTH = 100\n",
    "PARAGRAPH_EMB_DIM = 768\n",
    "NUM_TAGS = 12\n",
    "\n",
    "model = LSTMmodel(INPUT_LENGTH, PARAGRAPH_EMB_DIM, NUM_TAGS)\n",
    "model.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train(i):\n",
    "    with open('save_model/feature_%d.pk' % i, 'rb') as f:\n",
    "        feature = pickle.load(f)\n",
    "    \n",
    "    tags = train_tags[i*5000:(i+1)*5000]\n",
    "    if i == 1:\n",
    "        tags = tags[1000:]\n",
    "    if i == 0:\n",
    "        feature = feature[0:5000]\n",
    "    \n",
    "    X, rawY = [], [] # X is 3D: article, paragraph, embedding; Y is 2D: article, paragraph\n",
    "    for f, t in zip(feature, tags):\n",
    "        while len(f) < INPUT_LENGTH:\n",
    "            f.append(np.zeros(PARAGRAPH_EMB_DIM))\n",
    "        while len(t) < INPUT_LENGTH:\n",
    "            t.append(0)\n",
    "        f = f[0:INPUT_LENGTH]\n",
    "        t = t[0:INPUT_LENGTH]\n",
    "        X.append(f)\n",
    "        rawY.append(t)\n",
    "    \n",
    "    Y = [to_categorical(y, num_classes=NUM_TAGS) for y in rawY] # Y is now 3D\n",
    "    return X, Y\n",
    "\n",
    "        \n",
    "def get_test(i):\n",
    "    with open('save_model/feature_%d.pk' % i, 'rb') as f:\n",
    "        feature = pickle.load(f)\n",
    "    tags = train_tags[i*5000:(i+1)*5000]\n",
    "    X, rawY = [], [] # X is 3D: article, paragraph, embedding; Y is 2D: article, paragraph\n",
    "    for f, t in zip(feature, tags):\n",
    "        while len(f) < INPUT_LENGTH:\n",
    "            f.append(np.zeros(PARAGRAPH_EMB_DIM))\n",
    "        while len(t) < INPUT_LENGTH:\n",
    "            t.append(0)\n",
    "        f = f[0:INPUT_LENGTH]\n",
    "        t = t[0:INPUT_LENGTH]\n",
    "        X.append(f)\n",
    "        rawY.append(t)\n",
    "    \n",
    "    Y = [to_categorical(y, num_classes=NUM_TAGS) for y in rawY] # Y is now 3D\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "testPickleID = 12\n",
    "testX, testY = get_test(testPickleID)\n",
    "def test_accuracy(X=testX, Y=testY):\n",
    "    # Predict on test\n",
    "    test_pred = model.model.predict(np.array(testX), verbose=1)\n",
    "    truecnt = 0\n",
    "    falsecnt = 0\n",
    "    _max = 0\n",
    "    _maxarg = 0\n",
    "    for (i, pred) in enumerate(test_pred):\n",
    "        tcnt = 0\n",
    "        fcnt = 0\n",
    "        for j, p in enumerate(pred):\n",
    "            if np.argmax(testY[i][j]) != 0:\n",
    "                if np.argmax(p) == np.argmax(testY[i][j]):\n",
    "                    tcnt += 1\n",
    "                else:\n",
    "                    fcnt += 1\n",
    "        sample_acc = tcnt/(tcnt+fcnt)\n",
    "        if sample_acc > _max:\n",
    "            _max = sample_acc\n",
    "            _maxarg = i\n",
    "        truecnt += tcnt\n",
    "        falsecnt += fcnt\n",
    "        \n",
    "    acc = truecnt/(truecnt+falsecnt)\n",
    "    print('True: %d, False: %d, Acc: %f' % (truecnt, falsecnt, acc))\n",
    "    return acc, _max, _maxarg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# load data\\ntags = train_tags[6000:10000]\\nX, rawY = [], [] # X is 3D: article, paragraph, embedding; Y is 2D: article, paragraph\\nfor f, t in zip(feature, tags):\\n    while len(f) < INPUT_LENGTH:\\n        f.append(np.zeros(PARAGRAPH_EMB_DIM))\\n    while len(t) < INPUT_LENGTH:\\n        t.append(0)\\n    f = f[0:INPUT_LENGTH]\\n    t = t[0:INPUT_LENGTH]\\n    X.append(f)\\n    rawY.append(t)\\n    \\nY = [to_categorical(y, num_classes=NUM_TAGS) for y in rawY] # Y is now 3D\\n\\ndata_size = len(X)\\ntrain_size = int(data_size * 0.9)\\ntrainX, trainY = X[:train_size], Y[:train_size]\\ntestX, testY = X[train_size:], Y[train_size:]\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# load data\n",
    "tags = train_tags[6000:10000]\n",
    "X, rawY = [], [] # X is 3D: article, paragraph, embedding; Y is 2D: article, paragraph\n",
    "for f, t in zip(feature, tags):\n",
    "    while len(f) < INPUT_LENGTH:\n",
    "        f.append(np.zeros(PARAGRAPH_EMB_DIM))\n",
    "    while len(t) < INPUT_LENGTH:\n",
    "        t.append(0)\n",
    "    f = f[0:INPUT_LENGTH]\n",
    "    t = t[0:INPUT_LENGTH]\n",
    "    X.append(f)\n",
    "    rawY.append(t)\n",
    "    \n",
    "Y = [to_categorical(y, num_classes=NUM_TAGS) for y in rawY] # Y is now 3D\n",
    "\n",
    "data_size = len(X)\n",
    "train_size = int(data_size * 0.9)\n",
    "trainX, trainY = X[:train_size], Y[:train_size]\n",
    "testX, testY = X[train_size:], Y[train_size:]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/4\n",
      "4500/4500 [==============================] - 72s 16ms/step - loss: 0.0086 - crf_accuracy: 0.9009 - val_loss: 0.0120 - val_crf_accuracy: 0.8979\n",
      "Epoch 2/4\n",
      "4500/4500 [==============================] - 235s 52ms/step - loss: 0.0049 - crf_accuracy: 0.9026 - val_loss: 0.0098 - val_crf_accuracy: 0.8980\n",
      "Epoch 3/4\n",
      "4500/4500 [==============================] - 236s 52ms/step - loss: 9.6103e-04 - crf_accuracy: 0.9038 - val_loss: 0.0073 - val_crf_accuracy: 0.9002\n",
      "Epoch 4/4\n",
      "4500/4500 [==============================] - 237s 53ms/step - loss: -0.0025 - crf_accuracy: 0.9051 - val_loss: 0.0054 - val_crf_accuracy: 0.9005\n",
      "5000/5000 [==============================] - 120s 24ms/step\n",
      "True: 127159, False: 46702, Acc: 0.731383\n",
      "Saved to save_model/base_100n_1_12.h5\n",
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/4\n",
      "4500/4500 [==============================] - 237s 53ms/step - loss: 0.0034 - crf_accuracy: 0.9009 - val_loss: -0.0085 - val_crf_accuracy: 0.9062\n",
      "Epoch 2/4\n",
      "4500/4500 [==============================] - 238s 53ms/step - loss: -8.0440e-04 - crf_accuracy: 0.9025 - val_loss: -0.0108 - val_crf_accuracy: 0.9082\n",
      "Epoch 3/4\n",
      "4500/4500 [==============================] - 238s 53ms/step - loss: -0.0042 - crf_accuracy: 0.9033 - val_loss: -0.0115 - val_crf_accuracy: 0.9073\n",
      "Epoch 4/4\n",
      "4500/4500 [==============================] - 238s 53ms/step - loss: -0.0078 - crf_accuracy: 0.9053 - val_loss: -0.0139 - val_crf_accuracy: 0.9091\n",
      "5000/5000 [==============================] - 119s 24ms/step\n",
      "True: 127143, False: 46718, Acc: 0.731291\n",
      "Saved to save_model/base_100n_1_11.h5\n",
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/4\n",
      "4500/4500 [==============================] - 239s 53ms/step - loss: -0.0056 - crf_accuracy: 0.9032 - val_loss: -0.0101 - val_crf_accuracy: 0.9067\n",
      "Epoch 2/4\n",
      "4500/4500 [==============================] - 238s 53ms/step - loss: -0.0097 - crf_accuracy: 0.9047 - val_loss: -0.0109 - val_crf_accuracy: 0.9055\n",
      "Epoch 3/4\n",
      "4500/4500 [==============================] - 81s 18ms/step - loss: -0.0136 - crf_accuracy: 0.9053 - val_loss: -0.0133 - val_crf_accuracy: 0.9046\n",
      "Epoch 4/4\n",
      "4500/4500 [==============================] - 62s 14ms/step - loss: -0.0169 - crf_accuracy: 0.9068 - val_loss: -0.0150 - val_crf_accuracy: 0.9071\n",
      "5000/5000 [==============================] - 28s 6ms/step\n",
      "True: 127045, False: 46816, Acc: 0.730727\n",
      "Saved to save_model/base_100n_1_10.h5\n",
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/4\n",
      "4500/4500 [==============================] - 60s 13ms/step - loss: -0.0072 - crf_accuracy: 0.9007 - val_loss: -0.0219 - val_crf_accuracy: 0.9076\n",
      "Epoch 2/4\n",
      "4500/4500 [==============================] - 60s 13ms/step - loss: -0.0116 - crf_accuracy: 0.9020 - val_loss: -0.0230 - val_crf_accuracy: 0.9067\n",
      "Epoch 3/4\n",
      "4500/4500 [==============================] - 60s 13ms/step - loss: -0.0150 - crf_accuracy: 0.9031 - val_loss: -0.0231 - val_crf_accuracy: 0.9045\n",
      "Epoch 4/4\n",
      "4500/4500 [==============================] - 68s 15ms/step - loss: -0.0187 - crf_accuracy: 0.9046 - val_loss: -0.0270 - val_crf_accuracy: 0.9078\n",
      "5000/5000 [==============================] - 120s 24ms/step\n",
      "True: 127176, False: 46685, Acc: 0.731481\n",
      "Saved to save_model/base_100n_1_9.h5\n",
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/4\n",
      "4500/4500 [==============================] - 240s 53ms/step - loss: -0.0143 - crf_accuracy: 0.9021 - val_loss: -0.0266 - val_crf_accuracy: 0.9067\n",
      "Epoch 2/4\n",
      "4500/4500 [==============================] - 240s 53ms/step - loss: -0.0188 - crf_accuracy: 0.9033 - val_loss: -0.0262 - val_crf_accuracy: 0.9075\n",
      "Epoch 3/4\n",
      "4500/4500 [==============================] - 240s 53ms/step - loss: -0.0225 - crf_accuracy: 0.9043 - val_loss: -0.0296 - val_crf_accuracy: 0.9066\n",
      "Epoch 4/4\n",
      "4500/4500 [==============================] - 241s 54ms/step - loss: -0.0256 - crf_accuracy: 0.9057 - val_loss: -0.0309 - val_crf_accuracy: 0.9074\n",
      "5000/5000 [==============================] - 120s 24ms/step\n",
      "True: 127015, False: 46846, Acc: 0.730555\n",
      "Saved to save_model/base_100n_1_8.h5\n",
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/4\n",
      "4500/4500 [==============================] - 241s 53ms/step - loss: -0.0223 - crf_accuracy: 0.9030 - val_loss: -0.0232 - val_crf_accuracy: 0.9043\n",
      "Epoch 2/4\n",
      "4500/4500 [==============================] - 239s 53ms/step - loss: -0.0261 - crf_accuracy: 0.9044 - val_loss: -0.0256 - val_crf_accuracy: 0.9040\n",
      "Epoch 3/4\n",
      "4500/4500 [==============================] - 239s 53ms/step - loss: -0.0298 - crf_accuracy: 0.9051 - val_loss: -0.0288 - val_crf_accuracy: 0.9044\n",
      "Epoch 4/4\n",
      "4500/4500 [==============================] - 241s 53ms/step - loss: -0.0328 - crf_accuracy: 0.9066 - val_loss: -0.0287 - val_crf_accuracy: 0.9038\n",
      "5000/5000 [==============================] - 120s 24ms/step\n",
      "True: 126417, False: 47444, Acc: 0.727115\n",
      "Saved to save_model/base_100n_1_7.h5\n",
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/4\n",
      "4500/4500 [==============================] - 113s 25ms/step - loss: -0.0330 - crf_accuracy: 0.9060 - val_loss: -0.0224 - val_crf_accuracy: 0.8993\n",
      "Epoch 2/4\n",
      "4500/4500 [==============================] - 61s 14ms/step - loss: -0.0376 - crf_accuracy: 0.9079 - val_loss: -0.0241 - val_crf_accuracy: 0.9000\n",
      "Epoch 3/4\n",
      "4500/4500 [==============================] - 60s 13ms/step - loss: -0.0406 - crf_accuracy: 0.9085 - val_loss: -0.0265 - val_crf_accuracy: 0.8985\n",
      "Epoch 4/4\n",
      "4500/4500 [==============================] - 60s 13ms/step - loss: -0.0452 - crf_accuracy: 0.9105 - val_loss: -0.0280 - val_crf_accuracy: 0.9012\n",
      "5000/5000 [==============================] - 28s 6ms/step\n",
      "True: 127634, False: 46227, Acc: 0.734115\n",
      "Saved to save_model/base_100n_1_6.h5\n",
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/4\n",
      "4500/4500 [==============================] - 60s 13ms/step - loss: -0.0411 - crf_accuracy: 0.9076 - val_loss: -0.0382 - val_crf_accuracy: 0.9049\n",
      "Epoch 2/4\n",
      "4500/4500 [==============================] - 60s 13ms/step - loss: -0.0454 - crf_accuracy: 0.9093 - val_loss: -0.0387 - val_crf_accuracy: 0.9048\n",
      "Epoch 3/4\n",
      "4500/4500 [==============================] - 228s 51ms/step - loss: -0.0494 - crf_accuracy: 0.9111 - val_loss: -0.0404 - val_crf_accuracy: 0.9067\n",
      "Epoch 4/4\n",
      "4500/4500 [==============================] - 238s 53ms/step - loss: -0.0531 - crf_accuracy: 0.9117 - val_loss: -0.0420 - val_crf_accuracy: 0.9061\n",
      "5000/5000 [==============================] - 119s 24ms/step\n",
      "True: 127967, False: 45894, Acc: 0.736031\n",
      "Saved to save_model/base_100n_1_5.h5\n",
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/4\n",
      "4500/4500 [==============================] - 240s 53ms/step - loss: -0.0486 - crf_accuracy: 0.9088 - val_loss: -0.0500 - val_crf_accuracy: 0.9090\n",
      "Epoch 2/4\n",
      "4500/4500 [==============================] - 241s 54ms/step - loss: -0.0532 - crf_accuracy: 0.9101 - val_loss: -0.0522 - val_crf_accuracy: 0.9101\n",
      "Epoch 3/4\n",
      "4500/4500 [==============================] - 240s 53ms/step - loss: -0.0570 - crf_accuracy: 0.9112 - val_loss: -0.0541 - val_crf_accuracy: 0.9114\n",
      "Epoch 4/4\n",
      "4500/4500 [==============================] - 241s 54ms/step - loss: -0.0605 - crf_accuracy: 0.9127 - val_loss: -0.0558 - val_crf_accuracy: 0.9109\n",
      "5000/5000 [==============================] - 119s 24ms/step\n",
      "True: 127389, False: 46472, Acc: 0.732706\n",
      "Saved to save_model/base_100n_1_4.h5\n",
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/4\n",
      " 928/4500 [=====>........................] - ETA: 2:59 - loss: -0.0563 - crf_accuracy: 0.9096"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-a13d1154dea9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mtrainX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'save_model/base_100n_%d_%d.h5'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/anaconda3/envs/tfpy3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train\n",
    "model.model.load_weights('save_model/base_100n_1_5.h5')\n",
    "for i in range(5):\n",
    "    for j in range(15, 4, -1):\n",
    "        trainX, trainY = get_train(j)\n",
    "        model.model.fit(np.array(trainX), np.array(trainY), batch_size=32, epochs=1, validation_split=0.1)\n",
    "        acc, _m, _marg = test_accuracy()\n",
    "    fname = 'save_model/base_100nn_%d.h5' % (i+1)\n",
    "    print('Saved to ' + fname)\n",
    "    model.model.save_weights(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "# plt.style.use(\"ggplot\")\n",
    "# plt.figure(figsize=(12,12))\n",
    "# plt.plot(hist[\"acc\"])\n",
    "# plt.plot(hist[\"val_acc\"])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfpy3",
   "language": "python",
   "name": "tfpy3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
