{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Input\n",
    "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\n",
    "from keras_contrib.layers.crf import CRF\n",
    "from keras_contrib.utils import save_load_utils\n",
    "from keras_contrib.metrics import crf_accuracy\n",
    "from keras_contrib.losses import crf_loss\n",
    "from keras.utils import to_categorical\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import load_model\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "import pickle, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BERT_BASE = os.path.join(os.getcwd(), 'bert/bert_model/uncased_L-12_H-768_A-12')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMmodel:\n",
    "    def __init__(self, input_length, para_emb_dim, num_tags, hidden_dim=200, dropout=0.5):\n",
    "        self.num_tags = num_tags\n",
    "        self.model = Sequential()\n",
    "        self.model.add(Bidirectional(LSTM(hidden_dim, return_sequences=True), input_shape=(input_length, para_emb_dim)))\n",
    "        self.model.add(Dropout(dropout))\n",
    "        # self.model.add(Bidirectional(LSTM(hidden_dim, return_sequences=True), input_shape=(input_length, para_emb_dim)))\n",
    "        # self.model.add(Dropout(dropout))\n",
    "        self.model.add(TimeDistributed(Dense(self.num_tags)))\n",
    "        crf = CRF(self.num_tags)\n",
    "        self.model.add(crf)\n",
    "        self.model.compile('rmsprop', loss=crf_loss, metrics=[crf_accuracy])\n",
    "    \n",
    "    def save_model(self, filepath):\n",
    "        save_load_utils.save_all_weights(self.model, filepath)\n",
    "    \n",
    "    def restore_model(self, filepath):\n",
    "        save_load_utils.load_all_weights(self.model, filepath)\n",
    "        \n",
    "    def train(self, trainX, trainY, batch_size=32, epochs=10, validation_split=0.1, verbose=1):\n",
    "        return self.model.fit(trainX, np.array(trainY), batch_size=batch_size, epochs=epochs, \n",
    "                             validation_split=validation_split, verbose=verbose)\n",
    "    \n",
    "    @staticmethod\n",
    "    def myloss(y_true, y_pred):   \n",
    "        y_pred /= tf.reduce_sum(y_pred, -1, True)\n",
    "        # manual computation of crossentropy\n",
    "        y_pred = K.clip(y_pred, K.epsilon(), 1. - K.epsilon())\n",
    "        return -tf.reduce_sum(y_true * tf.log(y_pred), -1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114975 114975 114975\n"
     ]
    }
   ],
   "source": [
    "# from Dataprocessor import Dataprocessor\n",
    "\n",
    "# filelist = [('data/%d.json' % i) for i in range(500)]\n",
    "# processor = Dataprocessor()\n",
    "# train_texts, train_tags, train_rawtags = processor.load_data(filelist)\n",
    "\n",
    "# save_train_data(train_texts, train_tags, train_rawtags)\n",
    "train_texts, train_tags, train_rawtags = load_train_data()\n",
    "print(len(train_texts), len(train_tags), len(train_rawtags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert_utils import get_all_features\n",
    "\n",
    "bert_config_file = os.path.join(BERT_BASE, 'bert_config.json')\n",
    "vocab_file = os.path.join(BERT_BASE, 'vocab.txt')\n",
    "bert_checkpoint = os.path.join(BERT_BASE, 'bert_model.ckpt')\n",
    "    \n",
    "# feature = get_all_features(train_texts[:], bert_config_file, vocab_file, bert_checkpoint)\n",
    "# with open('save_model/feature_1.pk', 'rb') as f:\n",
    "#     feature = pickle.load(f)\n",
    "# print(len(feature))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional_1 (Bidirection (None, 100, 400)          1550400   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100, 400)          0         \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 100, 12)           4812      \n",
      "_________________________________________________________________\n",
      "crf_1 (CRF)                  (None, 100, 12)           324       \n",
      "=================================================================\n",
      "Total params: 1,555,536\n",
      "Trainable params: 1,555,536\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "INPUT_LENGTH = 100\n",
    "PARAGRAPH_EMB_DIM = 768\n",
    "NUM_TAGS = 12\n",
    "\n",
    "model = LSTMmodel(INPUT_LENGTH, PARAGRAPH_EMB_DIM, NUM_TAGS)\n",
    "model.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train(i):\n",
    "    with open('save_model/feature_%d.pk' % i, 'rb') as f:\n",
    "        feature = pickle.load(f)\n",
    "    \n",
    "    tags = train_tags[i*5000:(i+1)*5000]\n",
    "    if i == 1:\n",
    "        tags = tags[1000:]\n",
    "    if i == 0:\n",
    "        feature = feature[0:5000]\n",
    "    \n",
    "    X, rawY = [], [] # X is 3D: article, paragraph, embedding; Y is 2D: article, paragraph\n",
    "    for f, t in zip(feature, tags):\n",
    "        while len(f) < INPUT_LENGTH:\n",
    "            f.append(np.zeros(PARAGRAPH_EMB_DIM))\n",
    "        while len(t) < INPUT_LENGTH:\n",
    "            t.append(0)\n",
    "        f = f[0:INPUT_LENGTH]\n",
    "        t = t[0:INPUT_LENGTH]\n",
    "        X.append(f)\n",
    "        rawY.append(t)\n",
    "    \n",
    "    Y = [to_categorical(y, num_classes=NUM_TAGS) for y in rawY] # Y is now 3D\n",
    "    return X, Y\n",
    "\n",
    "        \n",
    "def get_test(i):\n",
    "    with open('save_model/feature_%d.pk' % i, 'rb') as f:\n",
    "        feature = pickle.load(f)\n",
    "    tags = train_tags[i*5000:(i+1)*5000]\n",
    "    X, rawY = [], [] # X is 3D: article, paragraph, embedding; Y is 2D: article, paragraph\n",
    "    for f, t in zip(feature, tags):\n",
    "        while len(f) < INPUT_LENGTH:\n",
    "            f.append(np.zeros(PARAGRAPH_EMB_DIM))\n",
    "        while len(t) < INPUT_LENGTH:\n",
    "            t.append(0)\n",
    "        f = f[0:INPUT_LENGTH]\n",
    "        t = t[0:INPUT_LENGTH]\n",
    "        X.append(f)\n",
    "        rawY.append(t)\n",
    "    \n",
    "    Y = [to_categorical(y, num_classes=NUM_TAGS) for y in rawY] # Y is now 3D\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "testPickleID = 12\n",
    "testX, testY = get_test(testPickleID)\n",
    "def test_accuracy():\n",
    "    # Predict on test\n",
    "    test_pred = model.model.predict(np.array(testX), verbose=1)\n",
    "    truecnt = 0\n",
    "    falsecnt = 0\n",
    "    for (i, pred) in enumerate(test_pred):\n",
    "        for j, p in enumerate(pred):\n",
    "            if np.argmax(testY[i][j]) != 0:\n",
    "                if np.argmax(p) == np.argmax(testY[i][j]):\n",
    "                    truecnt += 1\n",
    "                else:\n",
    "                    falsecnt += 1\n",
    "    acc = truecnt/(truecnt+falsecnt)\n",
    "    print('True: %d, False: %d, Acc: %f' % (truecnt, falsecnt, acc))\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# load data\\ntags = train_tags[6000:10000]\\nX, rawY = [], [] # X is 3D: article, paragraph, embedding; Y is 2D: article, paragraph\\nfor f, t in zip(feature, tags):\\n    while len(f) < INPUT_LENGTH:\\n        f.append(np.zeros(PARAGRAPH_EMB_DIM))\\n    while len(t) < INPUT_LENGTH:\\n        t.append(0)\\n    f = f[0:INPUT_LENGTH]\\n    t = t[0:INPUT_LENGTH]\\n    X.append(f)\\n    rawY.append(t)\\n    \\nY = [to_categorical(y, num_classes=NUM_TAGS) for y in rawY] # Y is now 3D\\n\\ndata_size = len(X)\\ntrain_size = int(data_size * 0.9)\\ntrainX, trainY = X[:train_size], Y[:train_size]\\ntestX, testY = X[train_size:], Y[train_size:]\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# load data\n",
    "tags = train_tags[6000:10000]\n",
    "X, rawY = [], [] # X is 3D: article, paragraph, embedding; Y is 2D: article, paragraph\n",
    "for f, t in zip(feature, tags):\n",
    "    while len(f) < INPUT_LENGTH:\n",
    "        f.append(np.zeros(PARAGRAPH_EMB_DIM))\n",
    "    while len(t) < INPUT_LENGTH:\n",
    "        t.append(0)\n",
    "    f = f[0:INPUT_LENGTH]\n",
    "    t = t[0:INPUT_LENGTH]\n",
    "    X.append(f)\n",
    "    rawY.append(t)\n",
    "    \n",
    "Y = [to_categorical(y, num_classes=NUM_TAGS) for y in rawY] # Y is now 3D\n",
    "\n",
    "data_size = len(X)\n",
    "train_size = int(data_size * 0.9)\n",
    "trainX, trainY = X[:train_size], Y[:train_size]\n",
    "testX, testY = X[train_size:], Y[train_size:]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/4\n",
      "4500/4500 [==============================] - 72s 16ms/step - loss: 0.0086 - crf_accuracy: 0.9009 - val_loss: 0.0120 - val_crf_accuracy: 0.8979\n",
      "Epoch 2/4\n",
      "4500/4500 [==============================] - 235s 52ms/step - loss: 0.0049 - crf_accuracy: 0.9026 - val_loss: 0.0098 - val_crf_accuracy: 0.8980\n",
      "Epoch 3/4\n",
      "4500/4500 [==============================] - 236s 52ms/step - loss: 9.6103e-04 - crf_accuracy: 0.9038 - val_loss: 0.0073 - val_crf_accuracy: 0.9002\n",
      "Epoch 4/4\n",
      "4500/4500 [==============================] - 237s 53ms/step - loss: -0.0025 - crf_accuracy: 0.9051 - val_loss: 0.0054 - val_crf_accuracy: 0.9005\n",
      "5000/5000 [==============================] - 120s 24ms/step\n",
      "True: 127159, False: 46702, Acc: 0.731383\n",
      "Saved to save_model/base_100n_1_12.h5\n",
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/4\n",
      "4500/4500 [==============================] - 237s 53ms/step - loss: 0.0034 - crf_accuracy: 0.9009 - val_loss: -0.0085 - val_crf_accuracy: 0.9062\n",
      "Epoch 2/4\n",
      "4500/4500 [==============================] - 238s 53ms/step - loss: -8.0440e-04 - crf_accuracy: 0.9025 - val_loss: -0.0108 - val_crf_accuracy: 0.9082\n",
      "Epoch 3/4\n",
      "4500/4500 [==============================] - 238s 53ms/step - loss: -0.0042 - crf_accuracy: 0.9033 - val_loss: -0.0115 - val_crf_accuracy: 0.9073\n",
      "Epoch 4/4\n",
      "4500/4500 [==============================] - 238s 53ms/step - loss: -0.0078 - crf_accuracy: 0.9053 - val_loss: -0.0139 - val_crf_accuracy: 0.9091\n",
      "5000/5000 [==============================] - 119s 24ms/step\n",
      "True: 127143, False: 46718, Acc: 0.731291\n",
      "Saved to save_model/base_100n_1_11.h5\n",
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/4\n",
      "4500/4500 [==============================] - 239s 53ms/step - loss: -0.0056 - crf_accuracy: 0.9032 - val_loss: -0.0101 - val_crf_accuracy: 0.9067\n",
      "Epoch 2/4\n",
      "4500/4500 [==============================] - 238s 53ms/step - loss: -0.0097 - crf_accuracy: 0.9047 - val_loss: -0.0109 - val_crf_accuracy: 0.9055\n",
      "Epoch 3/4\n",
      "4500/4500 [==============================] - 81s 18ms/step - loss: -0.0136 - crf_accuracy: 0.9053 - val_loss: -0.0133 - val_crf_accuracy: 0.9046\n",
      "Epoch 4/4\n",
      "4500/4500 [==============================] - 62s 14ms/step - loss: -0.0169 - crf_accuracy: 0.9068 - val_loss: -0.0150 - val_crf_accuracy: 0.9071\n",
      "5000/5000 [==============================] - 28s 6ms/step\n",
      "True: 127045, False: 46816, Acc: 0.730727\n",
      "Saved to save_model/base_100n_1_10.h5\n",
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/4\n",
      "4500/4500 [==============================] - 60s 13ms/step - loss: -0.0072 - crf_accuracy: 0.9007 - val_loss: -0.0219 - val_crf_accuracy: 0.9076\n",
      "Epoch 2/4\n",
      "4500/4500 [==============================] - 60s 13ms/step - loss: -0.0116 - crf_accuracy: 0.9020 - val_loss: -0.0230 - val_crf_accuracy: 0.9067\n",
      "Epoch 3/4\n",
      "4500/4500 [==============================] - 60s 13ms/step - loss: -0.0150 - crf_accuracy: 0.9031 - val_loss: -0.0231 - val_crf_accuracy: 0.9045\n",
      "Epoch 4/4\n",
      "4500/4500 [==============================] - 68s 15ms/step - loss: -0.0187 - crf_accuracy: 0.9046 - val_loss: -0.0270 - val_crf_accuracy: 0.9078\n",
      "5000/5000 [==============================] - 120s 24ms/step\n",
      "True: 127176, False: 46685, Acc: 0.731481\n",
      "Saved to save_model/base_100n_1_9.h5\n",
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/4\n",
      "4500/4500 [==============================] - 240s 53ms/step - loss: -0.0143 - crf_accuracy: 0.9021 - val_loss: -0.0266 - val_crf_accuracy: 0.9067\n",
      "Epoch 2/4\n",
      "4500/4500 [==============================] - 240s 53ms/step - loss: -0.0188 - crf_accuracy: 0.9033 - val_loss: -0.0262 - val_crf_accuracy: 0.9075\n",
      "Epoch 3/4\n",
      "4500/4500 [==============================] - 240s 53ms/step - loss: -0.0225 - crf_accuracy: 0.9043 - val_loss: -0.0296 - val_crf_accuracy: 0.9066\n",
      "Epoch 4/4\n",
      "4500/4500 [==============================] - 241s 54ms/step - loss: -0.0256 - crf_accuracy: 0.9057 - val_loss: -0.0309 - val_crf_accuracy: 0.9074\n",
      "5000/5000 [==============================] - 120s 24ms/step\n",
      "True: 127015, False: 46846, Acc: 0.730555\n",
      "Saved to save_model/base_100n_1_8.h5\n",
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/4\n",
      "4500/4500 [==============================] - 241s 53ms/step - loss: -0.0223 - crf_accuracy: 0.9030 - val_loss: -0.0232 - val_crf_accuracy: 0.9043\n",
      "Epoch 2/4\n",
      "4500/4500 [==============================] - 239s 53ms/step - loss: -0.0261 - crf_accuracy: 0.9044 - val_loss: -0.0256 - val_crf_accuracy: 0.9040\n",
      "Epoch 3/4\n",
      "4500/4500 [==============================] - 239s 53ms/step - loss: -0.0298 - crf_accuracy: 0.9051 - val_loss: -0.0288 - val_crf_accuracy: 0.9044\n",
      "Epoch 4/4\n",
      "4500/4500 [==============================] - 241s 53ms/step - loss: -0.0328 - crf_accuracy: 0.9066 - val_loss: -0.0287 - val_crf_accuracy: 0.9038\n",
      "5000/5000 [==============================] - 120s 24ms/step\n",
      "True: 126417, False: 47444, Acc: 0.727115\n",
      "Saved to save_model/base_100n_1_7.h5\n",
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/4\n",
      "4500/4500 [==============================] - 113s 25ms/step - loss: -0.0330 - crf_accuracy: 0.9060 - val_loss: -0.0224 - val_crf_accuracy: 0.8993\n",
      "Epoch 2/4\n",
      "4500/4500 [==============================] - 61s 14ms/step - loss: -0.0376 - crf_accuracy: 0.9079 - val_loss: -0.0241 - val_crf_accuracy: 0.9000\n",
      "Epoch 3/4\n",
      "4500/4500 [==============================] - 60s 13ms/step - loss: -0.0406 - crf_accuracy: 0.9085 - val_loss: -0.0265 - val_crf_accuracy: 0.8985\n",
      "Epoch 4/4\n",
      "4500/4500 [==============================] - 60s 13ms/step - loss: -0.0452 - crf_accuracy: 0.9105 - val_loss: -0.0280 - val_crf_accuracy: 0.9012\n",
      "5000/5000 [==============================] - 28s 6ms/step\n",
      "True: 127634, False: 46227, Acc: 0.734115\n",
      "Saved to save_model/base_100n_1_6.h5\n",
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/4\n",
      "4500/4500 [==============================] - 60s 13ms/step - loss: -0.0411 - crf_accuracy: 0.9076 - val_loss: -0.0382 - val_crf_accuracy: 0.9049\n",
      "Epoch 2/4\n",
      "4500/4500 [==============================] - 60s 13ms/step - loss: -0.0454 - crf_accuracy: 0.9093 - val_loss: -0.0387 - val_crf_accuracy: 0.9048\n",
      "Epoch 3/4\n",
      "4384/4500 [============================>.] - ETA: 5s - loss: -0.0493 - crf_accuracy: 0.9110"
     ]
    }
   ],
   "source": [
    "# train\n",
    "model.model.load_weights('save_model/base_100_3_6.h5')\n",
    "for i in range(3):\n",
    "    for j in range(11, -1, -1):\n",
    "        trainX, trainY = get_train(j)\n",
    "        model.model.fit(np.array(trainX), np.array(trainY), batch_size=32, epochs=4, validation_split=0.1)\n",
    "        acc = test_accuracy()\n",
    "        fname = 'save_model/base_100n_%d_%d.h5' % (i+1, j+1)\n",
    "        print('Saved to ' + fname)\n",
    "        model.model.save_weights(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "# plt.style.use(\"ggplot\")\n",
    "# plt.figure(figsize=(12,12))\n",
    "# plt.plot(hist[\"acc\"])\n",
    "# plt.plot(hist[\"val_acc\"])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfpy3",
   "language": "python",
   "name": "tfpy3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
