{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Input\n",
    "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\n",
    "from keras_contrib.layers.crf import CRF\n",
    "from keras_contrib.utils import save_load_utils\n",
    "from keras_contrib.metrics import crf_accuracy\n",
    "from keras_contrib.losses import crf_loss\n",
    "from keras.utils import to_categorical\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import load_model\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "import pickle, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BERT_BASE = os.path.join(os.getcwd(), 'bert/bert_model/uncased_L-12_H-768_A-12')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMmodel:\n",
    "    def __init__(self, input_length, para_emb_dim, num_tags, hidden_dim=200, dropout=0.5):\n",
    "        self.num_tags = num_tags\n",
    "        self.model = Sequential()\n",
    "        self.model.add(Bidirectional(LSTM(hidden_dim, return_sequences=True), input_shape=(input_length, para_emb_dim)))\n",
    "        self.model.add(Dropout(dropout))\n",
    "        # self.model.add(Bidirectional(LSTM(hidden_dim, return_sequences=True), input_shape=(input_length, para_emb_dim)))\n",
    "        # self.model.add(Dropout(dropout))\n",
    "        self.model.add(TimeDistributed(Dense(self.num_tags)))\n",
    "        crf = CRF(self.num_tags)\n",
    "        self.model.add(crf)\n",
    "        self.model.compile('rmsprop', loss=crf_loss, metrics=[crf_accuracy])\n",
    "    \n",
    "    def save_model(self, filepath):\n",
    "        save_load_utils.save_all_weights(self.model, filepath)\n",
    "    \n",
    "    def restore_model(self, filepath):\n",
    "        save_load_utils.load_all_weights(self.model, filepath)\n",
    "        \n",
    "    def train(self, trainX, trainY, batch_size=32, epochs=10, validation_split=0.1, verbose=1):\n",
    "        return self.model.fit(trainX, np.array(trainY), batch_size=batch_size, epochs=epochs, \n",
    "                             validation_split=validation_split, verbose=verbose)\n",
    "    \n",
    "    @staticmethod\n",
    "    def myloss(y_true, y_pred):   \n",
    "        y_pred /= tf.reduce_sum(y_pred, -1, True)\n",
    "        # manual computation of crossentropy\n",
    "        y_pred = K.clip(y_pred, K.epsilon(), 1. - K.epsilon())\n",
    "        return -tf.reduce_sum(y_true * tf.log(y_pred), -1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114975 114975 114975\n"
     ]
    }
   ],
   "source": [
    "# from Dataprocessor import Dataprocessor\n",
    "\n",
    "# filelist = [('data/%d.json' % i) for i in range(500)]\n",
    "# processor = Dataprocessor()\n",
    "# train_texts, train_tags, train_rawtags = processor.load_data(filelist)\n",
    "\n",
    "# save_train_data(train_texts, train_tags, train_rawtags)\n",
    "train_texts, train_tags, train_rawtags = load_train_data()\n",
    "print(len(train_texts), len(train_tags), len(train_rawtags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert_utils import get_all_features\n",
    "\n",
    "bert_config_file = os.path.join(BERT_BASE, 'bert_config.json')\n",
    "vocab_file = os.path.join(BERT_BASE, 'vocab.txt')\n",
    "bert_checkpoint = os.path.join(BERT_BASE, 'bert_model.ckpt')\n",
    "    \n",
    "# feature = get_all_features(train_texts[:], bert_config_file, vocab_file, bert_checkpoint)\n",
    "# with open('save_model/feature_1.pk', 'rb') as f:\n",
    "#     feature = pickle.load(f)\n",
    "# print(len(feature))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional_1 (Bidirection (None, 100, 400)          1550400   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100, 400)          0         \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 100, 12)           4812      \n",
      "_________________________________________________________________\n",
      "crf_1 (CRF)                  (None, 100, 12)           324       \n",
      "=================================================================\n",
      "Total params: 1,555,536\n",
      "Trainable params: 1,555,536\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "INPUT_LENGTH = 100\n",
    "PARAGRAPH_EMB_DIM = 768\n",
    "NUM_TAGS = 12\n",
    "\n",
    "model = LSTMmodel(INPUT_LENGTH, PARAGRAPH_EMB_DIM, NUM_TAGS)\n",
    "model.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train(i):\n",
    "    with open('save_model/feature_%d.pk' % i, 'rb') as f:\n",
    "        feature = pickle.load(f)\n",
    "    \n",
    "    tags = train_tags[i*5000:(i+1)*5000]\n",
    "    \n",
    "    X, rawY = [], [] # X is 3D: article, paragraph, embedding; Y is 2D: article, paragraph\n",
    "    for f, t in zip(feature, tags):\n",
    "        while len(f) < INPUT_LENGTH:\n",
    "            f.append(np.zeros(PARAGRAPH_EMB_DIM))\n",
    "        while len(t) < INPUT_LENGTH:\n",
    "            t.append(0)\n",
    "        f = f[0:INPUT_LENGTH]\n",
    "        t = t[0:INPUT_LENGTH]\n",
    "        X.append(f)\n",
    "        rawY.append(t)\n",
    "    \n",
    "    Y = [to_categorical(y, num_classes=NUM_TAGS) for y in rawY] # Y is now 3D\n",
    "    return X, Y\n",
    "\n",
    "        \n",
    "def get_test(i):\n",
    "    with open('save_model/feature_%d.pk' % i, 'rb') as f:\n",
    "        feature = pickle.load(f)\n",
    "    tags = train_tags[i*5000:(i+1)*5000]\n",
    "    X, rawY = [], [] # X is 3D: article, paragraph, embedding; Y is 2D: article, paragraph\n",
    "    for f, t in zip(feature, tags):\n",
    "        while len(f) < INPUT_LENGTH:\n",
    "            f.append(np.zeros(PARAGRAPH_EMB_DIM))\n",
    "        while len(t) < INPUT_LENGTH:\n",
    "            t.append(0)\n",
    "        f = f[0:INPUT_LENGTH]\n",
    "        t = t[0:INPUT_LENGTH]\n",
    "        X.append(f)\n",
    "        rawY.append(t)\n",
    "    \n",
    "    Y = [to_categorical(y, num_classes=NUM_TAGS) for y in rawY] # Y is now 3D\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "testPickleID = 12\n",
    "testX, testY = get_test(testPickleID)\n",
    "def test_accuracy(X=testX, Y=testY):\n",
    "    # Predict on test\n",
    "    test_pred = model.model.predict(np.array(X), verbose=1)\n",
    "    truecnt = 0\n",
    "    falsecnt = 0\n",
    "    _max = 0\n",
    "    _maxarg = 0\n",
    "    for (i, pred) in enumerate(test_pred):\n",
    "        tcnt = 0\n",
    "        fcnt = 0\n",
    "        for j, p in enumerate(pred):\n",
    "            if np.argmax(Y[i][j]) != 0:\n",
    "                if np.argmax(p) == np.argmax(Y[i][j]):\n",
    "                    tcnt += 1\n",
    "                else:\n",
    "                    fcnt += 1\n",
    "            else:\n",
    "                break\n",
    "        sample_acc = tcnt/(tcnt+fcnt) if tcnt+fcnt != 0 else 0\n",
    "        if sample_acc > _max and j >= 6:\n",
    "            _max = sample_acc\n",
    "            _maxarg = i\n",
    "        truecnt += tcnt\n",
    "        falsecnt += fcnt\n",
    "        \n",
    "    acc = truecnt/(truecnt+falsecnt)\n",
    "    print('True: %d, False: %d, Acc: %f' % (truecnt, falsecnt, acc))\n",
    "    return acc, _max, _maxarg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# load data\\ntags = train_tags[6000:10000]\\nX, rawY = [], [] # X is 3D: article, paragraph, embedding; Y is 2D: article, paragraph\\nfor f, t in zip(feature, tags):\\n    while len(f) < INPUT_LENGTH:\\n        f.append(np.zeros(PARAGRAPH_EMB_DIM))\\n    while len(t) < INPUT_LENGTH:\\n        t.append(0)\\n    f = f[0:INPUT_LENGTH]\\n    t = t[0:INPUT_LENGTH]\\n    X.append(f)\\n    rawY.append(t)\\n    \\nY = [to_categorical(y, num_classes=NUM_TAGS) for y in rawY] # Y is now 3D\\n\\ndata_size = len(X)\\ntrain_size = int(data_size * 0.9)\\ntrainX, trainY = X[:train_size], Y[:train_size]\\ntestX, testY = X[train_size:], Y[train_size:]\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# load data\n",
    "tags = train_tags[6000:10000]\n",
    "X, rawY = [], [] # X is 3D: article, paragraph, embedding; Y is 2D: article, paragraph\n",
    "for f, t in zip(feature, tags):\n",
    "    while len(f) < INPUT_LENGTH:\n",
    "        f.append(np.zeros(PARAGRAPH_EMB_DIM))\n",
    "    while len(t) < INPUT_LENGTH:\n",
    "        t.append(0)\n",
    "    f = f[0:INPUT_LENGTH]\n",
    "    t = t[0:INPUT_LENGTH]\n",
    "    X.append(f)\n",
    "    rawY.append(t)\n",
    "    \n",
    "Y = [to_categorical(y, num_classes=NUM_TAGS) for y in rawY] # Y is now 3D\n",
    "\n",
    "data_size = len(X)\n",
    "train_size = int(data_size * 0.9)\n",
    "trainX, trainY = X[:train_size], Y[:train_size]\n",
    "testX, testY = X[train_size:], Y[train_size:]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/4\n",
      "4500/4500 [==============================] - 72s 16ms/step - loss: 0.0086 - crf_accuracy: 0.9009 - val_loss: 0.0120 - val_crf_accuracy: 0.8979\n",
      "Epoch 2/4\n",
      "4500/4500 [==============================] - 235s 52ms/step - loss: 0.0049 - crf_accuracy: 0.9026 - val_loss: 0.0098 - val_crf_accuracy: 0.8980\n",
      "Epoch 3/4\n",
      "4500/4500 [==============================] - 236s 52ms/step - loss: 9.6103e-04 - crf_accuracy: 0.9038 - val_loss: 0.0073 - val_crf_accuracy: 0.9002\n",
      "Epoch 4/4\n",
      "4500/4500 [==============================] - 237s 53ms/step - loss: -0.0025 - crf_accuracy: 0.9051 - val_loss: 0.0054 - val_crf_accuracy: 0.9005\n",
      "5000/5000 [==============================] - 120s 24ms/step\n",
      "True: 127159, False: 46702, Acc: 0.731383\n",
      "Saved to save_model/base_100n_1_12.h5\n",
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/4\n",
      "4500/4500 [==============================] - 237s 53ms/step - loss: 0.0034 - crf_accuracy: 0.9009 - val_loss: -0.0085 - val_crf_accuracy: 0.9062\n",
      "Epoch 2/4\n",
      "4500/4500 [==============================] - 238s 53ms/step - loss: -8.0440e-04 - crf_accuracy: 0.9025 - val_loss: -0.0108 - val_crf_accuracy: 0.9082\n",
      "Epoch 3/4\n",
      "4500/4500 [==============================] - 238s 53ms/step - loss: -0.0042 - crf_accuracy: 0.9033 - val_loss: -0.0115 - val_crf_accuracy: 0.9073\n",
      "Epoch 4/4\n",
      "4500/4500 [==============================] - 238s 53ms/step - loss: -0.0078 - crf_accuracy: 0.9053 - val_loss: -0.0139 - val_crf_accuracy: 0.9091\n",
      "5000/5000 [==============================] - 119s 24ms/step\n",
      "True: 127143, False: 46718, Acc: 0.731291\n",
      "Saved to save_model/base_100n_1_11.h5\n",
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/4\n",
      "4500/4500 [==============================] - 239s 53ms/step - loss: -0.0056 - crf_accuracy: 0.9032 - val_loss: -0.0101 - val_crf_accuracy: 0.9067\n",
      "Epoch 2/4\n",
      "4500/4500 [==============================] - 238s 53ms/step - loss: -0.0097 - crf_accuracy: 0.9047 - val_loss: -0.0109 - val_crf_accuracy: 0.9055\n",
      "Epoch 3/4\n",
      "4500/4500 [==============================] - 81s 18ms/step - loss: -0.0136 - crf_accuracy: 0.9053 - val_loss: -0.0133 - val_crf_accuracy: 0.9046\n",
      "Epoch 4/4\n",
      "4500/4500 [==============================] - 62s 14ms/step - loss: -0.0169 - crf_accuracy: 0.9068 - val_loss: -0.0150 - val_crf_accuracy: 0.9071\n",
      "5000/5000 [==============================] - 28s 6ms/step\n",
      "True: 127045, False: 46816, Acc: 0.730727\n",
      "Saved to save_model/base_100n_1_10.h5\n",
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/4\n",
      "4500/4500 [==============================] - 60s 13ms/step - loss: -0.0072 - crf_accuracy: 0.9007 - val_loss: -0.0219 - val_crf_accuracy: 0.9076\n",
      "Epoch 2/4\n",
      "4500/4500 [==============================] - 60s 13ms/step - loss: -0.0116 - crf_accuracy: 0.9020 - val_loss: -0.0230 - val_crf_accuracy: 0.9067\n",
      "Epoch 3/4\n",
      "4500/4500 [==============================] - 60s 13ms/step - loss: -0.0150 - crf_accuracy: 0.9031 - val_loss: -0.0231 - val_crf_accuracy: 0.9045\n",
      "Epoch 4/4\n",
      "4500/4500 [==============================] - 68s 15ms/step - loss: -0.0187 - crf_accuracy: 0.9046 - val_loss: -0.0270 - val_crf_accuracy: 0.9078\n",
      "5000/5000 [==============================] - 120s 24ms/step\n",
      "True: 127176, False: 46685, Acc: 0.731481\n",
      "Saved to save_model/base_100n_1_9.h5\n",
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/4\n",
      "4500/4500 [==============================] - 240s 53ms/step - loss: -0.0143 - crf_accuracy: 0.9021 - val_loss: -0.0266 - val_crf_accuracy: 0.9067\n",
      "Epoch 2/4\n",
      "4500/4500 [==============================] - 240s 53ms/step - loss: -0.0188 - crf_accuracy: 0.9033 - val_loss: -0.0262 - val_crf_accuracy: 0.9075\n",
      "Epoch 3/4\n",
      "4500/4500 [==============================] - 240s 53ms/step - loss: -0.0225 - crf_accuracy: 0.9043 - val_loss: -0.0296 - val_crf_accuracy: 0.9066\n",
      "Epoch 4/4\n",
      "4500/4500 [==============================] - 241s 54ms/step - loss: -0.0256 - crf_accuracy: 0.9057 - val_loss: -0.0309 - val_crf_accuracy: 0.9074\n",
      "5000/5000 [==============================] - 120s 24ms/step\n",
      "True: 127015, False: 46846, Acc: 0.730555\n",
      "Saved to save_model/base_100n_1_8.h5\n",
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/4\n",
      "4500/4500 [==============================] - 241s 53ms/step - loss: -0.0223 - crf_accuracy: 0.9030 - val_loss: -0.0232 - val_crf_accuracy: 0.9043\n",
      "Epoch 2/4\n",
      "4500/4500 [==============================] - 239s 53ms/step - loss: -0.0261 - crf_accuracy: 0.9044 - val_loss: -0.0256 - val_crf_accuracy: 0.9040\n",
      "Epoch 3/4\n",
      "4500/4500 [==============================] - 239s 53ms/step - loss: -0.0298 - crf_accuracy: 0.9051 - val_loss: -0.0288 - val_crf_accuracy: 0.9044\n",
      "Epoch 4/4\n",
      "4500/4500 [==============================] - 241s 53ms/step - loss: -0.0328 - crf_accuracy: 0.9066 - val_loss: -0.0287 - val_crf_accuracy: 0.9038\n",
      "5000/5000 [==============================] - 120s 24ms/step\n",
      "True: 126417, False: 47444, Acc: 0.727115\n",
      "Saved to save_model/base_100n_1_7.h5\n",
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/4\n",
      "4500/4500 [==============================] - 113s 25ms/step - loss: -0.0330 - crf_accuracy: 0.9060 - val_loss: -0.0224 - val_crf_accuracy: 0.8993\n",
      "Epoch 2/4\n",
      "4500/4500 [==============================] - 61s 14ms/step - loss: -0.0376 - crf_accuracy: 0.9079 - val_loss: -0.0241 - val_crf_accuracy: 0.9000\n",
      "Epoch 3/4\n",
      "4500/4500 [==============================] - 60s 13ms/step - loss: -0.0406 - crf_accuracy: 0.9085 - val_loss: -0.0265 - val_crf_accuracy: 0.8985\n",
      "Epoch 4/4\n",
      "4500/4500 [==============================] - 60s 13ms/step - loss: -0.0452 - crf_accuracy: 0.9105 - val_loss: -0.0280 - val_crf_accuracy: 0.9012\n",
      "5000/5000 [==============================] - 28s 6ms/step\n",
      "True: 127634, False: 46227, Acc: 0.734115\n",
      "Saved to save_model/base_100n_1_6.h5\n",
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/4\n",
      "4500/4500 [==============================] - 60s 13ms/step - loss: -0.0411 - crf_accuracy: 0.9076 - val_loss: -0.0382 - val_crf_accuracy: 0.9049\n",
      "Epoch 2/4\n",
      "4500/4500 [==============================] - 60s 13ms/step - loss: -0.0454 - crf_accuracy: 0.9093 - val_loss: -0.0387 - val_crf_accuracy: 0.9048\n",
      "Epoch 3/4\n",
      "4500/4500 [==============================] - 228s 51ms/step - loss: -0.0494 - crf_accuracy: 0.9111 - val_loss: -0.0404 - val_crf_accuracy: 0.9067\n",
      "Epoch 4/4\n",
      "4500/4500 [==============================] - 238s 53ms/step - loss: -0.0531 - crf_accuracy: 0.9117 - val_loss: -0.0420 - val_crf_accuracy: 0.9061\n",
      "5000/5000 [==============================] - 119s 24ms/step\n",
      "True: 127967, False: 45894, Acc: 0.736031\n",
      "Saved to save_model/base_100n_1_5.h5\n",
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/4\n",
      "4500/4500 [==============================] - 240s 53ms/step - loss: -0.0486 - crf_accuracy: 0.9088 - val_loss: -0.0500 - val_crf_accuracy: 0.9090\n",
      "Epoch 2/4\n",
      "4500/4500 [==============================] - 241s 54ms/step - loss: -0.0532 - crf_accuracy: 0.9101 - val_loss: -0.0522 - val_crf_accuracy: 0.9101\n",
      "Epoch 3/4\n",
      "4500/4500 [==============================] - 240s 53ms/step - loss: -0.0570 - crf_accuracy: 0.9112 - val_loss: -0.0541 - val_crf_accuracy: 0.9114\n",
      "Epoch 4/4\n",
      "4500/4500 [==============================] - 241s 54ms/step - loss: -0.0605 - crf_accuracy: 0.9127 - val_loss: -0.0558 - val_crf_accuracy: 0.9109\n",
      "5000/5000 [==============================] - 119s 24ms/step\n",
      "True: 127389, False: 46472, Acc: 0.732706\n",
      "Saved to save_model/base_100n_1_4.h5\n",
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/4\n",
      " 928/4500 [=====>........................] - ETA: 2:59 - loss: -0.0563 - crf_accuracy: 0.9096"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-a13d1154dea9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mtrainX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'save_model/base_100n_%d_%d.h5'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/anaconda3/envs/tfpy3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train\n",
    "model.model.load_weights('save_model/base_100n_1_5.h5')\n",
    "for i in range(5):\n",
    "    for j in range(15, -1, -1):\n",
    "        if j == testPickleID:\n",
    "            continue\n",
    "        trainX, trainY = get_train(j)\n",
    "        model.model.fit(np.array(trainX), np.array(trainY), batch_size=32, epochs=1, validation_split=0.1)\n",
    "        acc, _m, _marg = test_accuracy()\n",
    "    fname = 'save_model/base_100nn_%d.h5' % (i+1)\n",
    "    print('Saved to ' + fname)\n",
    "    model.model.save_weights(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "# plt.style.use(\"ggplot\")\n",
    "# plt.figure(figsize=(12,12))\n",
    "# plt.plot(hist[\"acc\"])\n",
    "# plt.plot(hist[\"val_acc\"])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 28s 6ms/step\n",
      "True: 127643, False: 43690, Acc: 0.745000\n",
      "0 0.7449995038900854 1.0 3\n",
      "4000/4000 [==============================] - 22s 6ms/step\n",
      "True: 32108, False: 103180, Acc: 0.237331\n",
      "1 0.23733073147655373 0.9473684210526315 3718\n",
      "5000/5000 [==============================] - 27s 5ms/step\n",
      "True: 126840, False: 45364, Acc: 0.736568\n",
      "2 0.7365682562542101 1.0 25\n",
      "5000/5000 [==============================] - 28s 6ms/step\n",
      "True: 124491, False: 43727, Acc: 0.740058\n",
      "3 0.7400575443769395 1.0 6\n",
      "5000/5000 [==============================] - 28s 6ms/step\n",
      "True: 128801, False: 41533, Acc: 0.756167\n",
      "4 0.7561672948442472 1.0 4\n",
      "5000/5000 [==============================] - 28s 6ms/step\n",
      "True: 128398, False: 43906, Acc: 0.745183\n",
      "5 0.7451829324914105 1.0 25\n",
      "5000/5000 [==============================] - 28s 6ms/step\n",
      "True: 127299, False: 45097, Acc: 0.738410\n",
      "6 0.7384104039536881 1.0 32\n",
      "5000/5000 [==============================] - 28s 6ms/step\n",
      "True: 125879, False: 45687, Acc: 0.733706\n",
      "7 0.7337059790401361 1.0 4\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-28e6937a8121>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtrainX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_m\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_marg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_m\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-31-0e17a5ab9863>\u001b[0m in \u001b[0;36mtest_accuracy\u001b[0;34m(X, Y)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtest_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtestX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtestY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# Predict on test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtest_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mtruecnt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mfalsecnt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.model.load_weights('save_model/base_100n_1_5.h5')\n",
    "for i in range(16):\n",
    "    trainX, trainY = get_train(i)\n",
    "    acc, _m, _marg = test_accuracy(trainX, trainY)\n",
    "    print(i, acc, _m, _marg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"The National College of Arts (Urdu: قومی کالج هنر\\u202c\\u200e or NCA) is a public art school located in Lahore Punjab, Pakistan. NCA is the oldest art school in Pakistan and the second oldest in South Asia. As of 2016, the college is ranked as Pakistan's top art school. NCA maintains five departments in fine art, design film and TV, musicology and architecture and consists of over 800 students. The college runs faculty and student exchange programs with School of Fine Arts, University of New South Wales, École nationale supérieure des Beaux-Arts and the Instituto Superior de Arte. It also hosts the UNESCO Chair in architecture.\", \"NCA was originally founded in 1875 as the Mayo School of Industrial Arts and was one of two art colleges created by the British Crown in British India in reaction to the Arts & Crafts Movement. The Mayo School of Industrial Arts was named in honor of the recently assassinated British Viceroy Lord Mayo in 1875. John Lockwood Kipling becoming the school's first principal, who was also appointed the first curator of the Lahore Museum, which opened the same year in an adjacent building. In 1958, the school was renamed to the National College of Arts. Designated the premier art institution in the country, it was transferred to the Department of Education from the Department of Industries in the 1960s. It received a degree-awarding status in 1985 and created its first graduate programs in 1999. In 2006, the school opened a second campus in Rawalpindi and received a university charter in June 2011.\", 'Department of Architecture', 'Department of Fine Arts', 'Department of Communication Design', 'Department of Ceramics Design', 'Department of Product Design', 'Department of Textile Design', 'Department of Musicology', 'Department of Film and Television', 'Department of Multimedia Arts', 'Department of YKI', 'Department of Interior Designing', 'Zahoor ul Akhlaq Gallery', 'Lahore campus', 'Rawalpindi campus', '1870-1890: Lockwood Kipling', '1890-1897: W.F.H. Andrews', '1897-1909: Percy Brown', '1903-1913: Bhai Ram Singh', '1913-1939: Hugh Lionel Heath', '1929-1942: S. N. Gupta', '1942-1947: Mian Muhammad Hussain', '1947-1953: Ghulam Nabi Malik', '1954-1956: Sidney Spedding', '1958-1961: M.R. Sponenburgh', '1949-1965: Qazi Mohammad rafique', '1961-1974: Shakir Ali', '!975 Khalid Iqbal', '1976-1983: Iqbal Hassan', '1984-1990: Abbasi Abidi', '1990-1994: Sajida Haider Vandal', '1995-1999: Salima Hashmi', '1999-2007: Sajida Haider Vandal', '2007-2010: Naazish Ata Ullah', '2010-2013: Fozia Qureshi (Acting), Ustad Bashir Ahmed (Acting), Sajjad Kousar (Acting), Dr. Shabnam Khan (Acting)', '2013–present: Murtaza Jafri', 'Bhagat Singh - Celebrated Indian Socialist Revolutionary', 'Sukhdev Thapar - Celebrated Indian Socialist Revolutionary', 'Mahmood Hayat - Pakistani artist and designer', 'Sumaira Tazeen - Pakistani miniature painter', 'Ali Zafar - Pakistani actor in Lollywood and Bollywood']\n"
     ]
    }
   ],
   "source": [
    "print(train_texts[8718])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('save_model/example.txt', 'w') as f:\n",
    "    for line in train_texts[8718]:\n",
    "        f.write(line + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfpy3",
   "language": "python",
   "name": "tfpy3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
